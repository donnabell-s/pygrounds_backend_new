{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a240fb62",
   "metadata": {},
   "source": [
    "# iBKT Model Fit & Predictive Validity Evaluation\n",
    "\n",
    "This notebook demonstrates how to evaluate an Individualized Bayesian Knowledge Tracing (iBKT) model using Model Fit (Log-Likelihood) and Predictive Validity (AUC-ROC) on mock session data for coding and non-coding tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f2dd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Import your BKT from the project (preferred)\n",
    "try:\n",
    "    from user_learning.adaptive_engine import BKTParams, bkt_update_once\n",
    "except Exception:\n",
    "    # Fallback minimal BKT to keep the notebook runnable\n",
    "    from dataclasses import dataclass\n",
    "    @dataclass\n",
    "    class BKTParams:\n",
    "        p_L0: float = 0.20\n",
    "        p_T: float = 0.10\n",
    "        p_T_wrong: float = 0.00\n",
    "        p_S: float = 0.10\n",
    "        p_G: float = 0.20\n",
    "        decay_wrong: float = 0.85\n",
    "        min_floor: float = 1e-6\n",
    "        max_ceiling: float = 1-1e-6\n",
    "    def bkt_update_once(p_know: float, correct: bool, p: BKTParams) -> float:\n",
    "        if correct:\n",
    "            num = p_know * (1 - p.p_S)\n",
    "            den = num + (1 - p_know) * p.p_G\n",
    "            pT = p.p_T\n",
    "        else:\n",
    "            num = p_know * p.p_S\n",
    "            den = num + (1 - p_know) * (1 - p.p_G)\n",
    "            pT = p.p_T_wrong\n",
    "        post = 0.0 if den == 0 else num / den\n",
    "        p_next = post + (1 - post) * pT\n",
    "        if not correct:\n",
    "            p_next *= p.decay_wrong\n",
    "        return max(p.min_floor, min(p.max_ceiling, p_next))\n",
    "\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe4af3",
   "metadata": {},
   "source": [
    "## Mock data generator (coding + non-coding)\n",
    "\n",
    "\n",
    "We will create mock response data for both coding and non-coding sessions. Each entry represents a learner's response sequence for a subtopic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e062695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subtopic_id</th>\n",
       "      <th>game_type</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>estimated_difficulty</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>coding</td>\n",
       "      <td>1</td>\n",
       "      <td>master</td>\n",
       "      <td>2025-10-21 14:02:36.841166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>non_coding</td>\n",
       "      <td>1</td>\n",
       "      <td>beginner</td>\n",
       "      <td>2025-10-21 14:03:06.841166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>non_coding</td>\n",
       "      <td>1</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2025-10-21 14:03:35.841166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>coding</td>\n",
       "      <td>1</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2025-10-21 14:04:04.841166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>non_coding</td>\n",
       "      <td>1</td>\n",
       "      <td>advanced</td>\n",
       "      <td>2025-10-21 14:04:33.841166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  subtopic_id   game_type  is_correct estimated_difficulty  \\\n",
       "0        1          101      coding           1               master   \n",
       "1        1          101  non_coding           1             beginner   \n",
       "2        1          101  non_coding           1         intermediate   \n",
       "3        1          101      coding           1         intermediate   \n",
       "4        1          101  non_coding           1             advanced   \n",
       "\n",
       "                   timestamp  \n",
       "0 2025-10-21 14:02:36.841166  \n",
       "1 2025-10-21 14:03:06.841166  \n",
       "2 2025-10-21 14:03:35.841166  \n",
       "3 2025-10-21 14:04:04.841166  \n",
       "4 2025-10-21 14:04:33.841166  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_mock_df_with_sessions(num_users=3, noncoding_sessions=6, coding_sessions=6,\n",
    "                               subtopic_pool=range(101, 121), p_correct_mu=0.7, p_correct_sigma=0.15):\n",
    "    rows = []\n",
    "    base = datetime.now()\n",
    "    diffs = [\"beginner\",\"intermediate\",\"advanced\",\"master\"]\n",
    "    sid = 1\n",
    "\n",
    "    for u in range(1, num_users+1):\n",
    "        # Non-coding sessions (≤10 Q each, subtopics can vary per question)\n",
    "        for _ in range(noncoding_sessions):\n",
    "            n_q = np.random.randint(6, 11)  # 6..10\n",
    "            p_acc = float(np.clip(np.random.normal(p_correct_mu, p_correct_sigma), 0.3, 0.95))\n",
    "            for q_idx in range(1, n_q+1):\n",
    "                sub = int(np.random.choice(subtopic_pool))\n",
    "                diff = np.random.choice(diffs, p=[0.35,0.40,0.20,0.05])\n",
    "                is_correct = int(np.random.rand() < p_acc)\n",
    "                tstamp = base + timedelta(minutes=sid, seconds=q_idx*15)\n",
    "                rows.append({\n",
    "                    \"user_id\": u,\n",
    "                    \"session_id\": f\"NC-{u}-{sid}\",\n",
    "                    \"q_idx\": q_idx,\n",
    "                    \"subtopic_id\": sub,\n",
    "                    \"game_type\": \"non_coding\",\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"estimated_difficulty\": diff,\n",
    "                    \"timestamp\": tstamp\n",
    "                })\n",
    "            sid += 1\n",
    "\n",
    "        # Coding sessions (exactly 1 Q each)\n",
    "        for _ in range(coding_sessions):\n",
    "            p_acc = float(np.clip(np.random.normal(p_correct_mu, p_correct_sigma), 0.3, 0.95))\n",
    "            sub = int(np.random.choice(subtopic_pool))\n",
    "            diff = np.random.choice(diffs, p=[0.35,0.40,0.20,0.05])\n",
    "            is_correct = int(np.random.rand() < p_acc)\n",
    "            tstamp = base + timedelta(minutes=sid)\n",
    "            rows.append({\n",
    "                \"user_id\": u,\n",
    "                \"session_id\": f\"C-{u}-{sid}\",\n",
    "                \"q_idx\": 1,\n",
    "                \"subtopic_id\": sub,\n",
    "                \"game_type\": \"coding\",\n",
    "                \"is_correct\": is_correct,\n",
    "                \"estimated_difficulty\": diff,\n",
    "                \"timestamp\": tstamp\n",
    "            })\n",
    "            sid += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"user_id\",\"timestamp\",\"session_id\",\"q_idx\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = make_mock_df()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac24b6b",
   "metadata": {},
   "source": [
    "## Evaluate Log-Likelihood and AUC-ROC (overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035eeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple iBKT update function (mock parameters)\n",
    "def ibkt_forward(responses, p_init=0.3, p_transit=0.2, p_guess=0.25, p_slip=0.1):\n",
    "    p_know = p_init\n",
    "    preds = []\n",
    "    for obs in responses:\n",
    "        # Predict before seeing response\n",
    "        p_correct = p_know * (1 - p_slip) + (1 - p_know) * p_guess\n",
    "        preds.append(p_correct)\n",
    "        # Update knowledge state\n",
    "        if obs == 1:\n",
    "            num = p_know * (1 - p_slip)\n",
    "            denom = num + (1 - p_know) * p_guess\n",
    "        else:\n",
    "            num = p_know * p_slip\n",
    "            denom = num + (1 - p_know) * (1 - p_guess)\n",
    "        p_know = num / denom if denom > 0 else p_know\n",
    "        # Transit to next state\n",
    "        p_know = p_know + (1 - p_know) * p_transit\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c5c67",
   "metadata": {},
   "source": [
    "## Stratified metrics (coding vs non-coding, difficulty bands)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933633e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for session_type, sessions in mock_data.items():\n",
    "    all_preds = []\n",
    "    all_obs = []\n",
    "    log_likelihood = 0.0\n",
    "    n = 0\n",
    "    for session in sessions:\n",
    "        preds = ibkt_forward(session['responses'])\n",
    "        obs = session['responses']\n",
    "        # Log-likelihood: sum log(p) for correct, log(1-p) for incorrect\n",
    "        for p, o in zip(preds, obs):\n",
    "            if o == 1:\n",
    "                log_likelihood += np.log(max(p, 1e-8))\n",
    "            else:\n",
    "                log_likelihood += np.log(max(1-p, 1e-8))\n",
    "            n += 1\n",
    "        all_preds.extend(preds)\n",
    "        all_obs.extend(obs)\n",
    "    avg_log_likelihood = log_likelihood / n if n > 0 else float('nan')\n",
    "    auc = roc_auc_score(all_obs, all_preds) if len(set(all_obs)) > 1 else float('nan')\n",
    "    results.append({'Session Type': session_type, 'Log-Likelihood': avg_log_likelihood, 'AUC-ROC': auc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8837c10",
   "metadata": {},
   "source": [
    "## Output Metrics in Summary Table\n",
    "\n",
    "Display the Log-Likelihood and AUC-ROC for each session type in a concise table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07d785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session Type</th>\n",
       "      <th>Log-Likelihood</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coding</td>\n",
       "      <td>-0.903199</td>\n",
       "      <td>0.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_coding</td>\n",
       "      <td>-0.741343</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Session Type  Log-Likelihood   AUC-ROC\n",
       "0       coding       -0.903199  0.229167\n",
       "1   non_coding       -0.741343  0.520833"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and print summary table\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e41f0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'session_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Sanity checks specific to PyGrounds session structure ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Non-coding sessions must have ≤10 questions\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     df[df\u001b[38;5;241m.\u001b[39mgame_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_coding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mle(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m     10\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-coding session exceeds 10 questions!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Coding sessions must have exactly 1 question\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     df[df\u001b[38;5;241m.\u001b[39mgame_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m     19\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA coding session has more than one question!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Donna\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8253\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8254\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8255\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8256\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8257\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8258\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8259\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8260\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8261\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8262\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Donna\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m    932\u001b[0m         obj,\n\u001b[0;32m    933\u001b[0m         keys,\n\u001b[0;32m    934\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    935\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m    936\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    937\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m    938\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m    939\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\Donna\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'session_id'"
     ]
    }
   ],
   "source": [
    "# --- Sanity checks specific to PyGrounds session structure ---\n",
    "\n",
    "# 1. Non-coding sessions must have ≤10 questions\n",
    "assert (\n",
    "    df[df.game_type == \"non_coding\"]\n",
    "    .groupby(\"session_id\")[\"q_idx\"]\n",
    "    .max()\n",
    "    .le(10)\n",
    "    .all()\n",
    "), \"Non-coding session exceeds 10 questions!\"\n",
    "\n",
    "# 2. Coding sessions must have exactly 1 question\n",
    "assert (\n",
    "    df[df.game_type == \"coding\"]\n",
    "    .groupby(\"session_id\")[\"q_idx\"]\n",
    "    .max()\n",
    "    .eq(1)\n",
    "    .all()\n",
    "), \"A coding session has more than one question!\"\n",
    "\n",
    "print(\"✅ Session structure checks passed.\")\n",
    "\n",
    "\n",
    "# --- Extra breakdowns: useful for debugging model behavior ---\n",
    "\n",
    "# Overall performance\n",
    "overall = eval_ibkt_ll_auc(df)\n",
    "print(f\"Overall LL={overall['avg_log_likelihood']:.4f} | AUC={overall['auc_roc']:.3f}\")\n",
    "\n",
    "# Breakdown by game type (coding vs non-coding)\n",
    "by_game = eval_by_group(df, \"game_type\")\n",
    "print(\"\\n=== Breakdown by Game Type ===\")\n",
    "display(by_game)\n",
    "\n",
    "# Breakdown by difficulty\n",
    "by_diff = eval_by_group(df, \"estimated_difficulty\")\n",
    "print(\"\\n=== Breakdown by Difficulty ===\")\n",
    "display(by_diff)\n",
    "\n",
    "# Breakdown by subtopic (optional)\n",
    "by_subtopic = eval_by_group(df, \"subtopic_id\")\n",
    "print(\"\\n=== Breakdown by Subtopic (sample of first 10) ===\")\n",
    "display(by_subtopic.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
