{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4ebbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iBKT Evaluation â€” single-notebook version\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Iterable, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d4a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game-type weights (so coding doesn't dominate too much)\n",
    "GAME_TYPE_WEIGHTS = {\"coding\": 2.0, \"non_coding\": 1.0}\n",
    "\n",
    "DEFAULT_TIME_LIMITS = {\n",
    "    \"debugging\": 300.0, \"hangman\": 300.0, \"crossword\": 300.0, \"wordsearch\": 300.0,\n",
    "}\n",
    "\n",
    "def _safe_float(v, default: float = 0.0) -> float:\n",
    "    try:\n",
    "        return float(v) if v is not None else default\n",
    "    except (TypeError, ValueError):\n",
    "        return default\n",
    "\n",
    "def _expected_time(entry: dict) -> float:\n",
    "    T = _safe_float(entry.get(\"time_limit\"), 0.0)\n",
    "    if T > 0:\n",
    "        return T\n",
    "    m = (entry.get(\"minigame_type\") or entry.get(\"game_type\") or \"\").strip().lower()\n",
    "    return DEFAULT_TIME_LIMITS.get(m, 300.0)\n",
    "\n",
    "def _observed_time(entry: dict) -> float:\n",
    "    t = _safe_float(entry.get(\"minigame_time_taken\"), 0.0)\n",
    "    T = _expected_time(entry)\n",
    "    return max(0.0, min(t, 2.0 * T))  # clamp huge pauses\n",
    "\n",
    "def _time_multiplier(entry: dict, is_correct: bool) -> float:\n",
    "    t = _observed_time(entry)\n",
    "    if t <= 0:\n",
    "        return 1.0\n",
    "    T = max(1e-6, _expected_time(entry))\n",
    "    r = min(2.0, max(0.0, t / T))  # observed/budget\n",
    "    r0, beta, alpha = 0.8, 2.0, 0.20\n",
    "    signed = 1.0 if is_correct else -1.0\n",
    "    mult = 1.0 + signed * alpha * math.tanh(beta * (r0 - r))\n",
    "    return max(0.90, min(1.10, mult))  # tighter clamp\n",
    "\n",
    "def _game_weight(entry: dict) -> float:\n",
    "    g = (entry.get(\"game_type\") or \"\").strip().lower()\n",
    "    return GAME_TYPE_WEIGHTS.get(g, GAME_TYPE_WEIGHTS[\"non_coding\"])\n",
    "\n",
    "def _norm_diff(d: Optional[str]) -> str:\n",
    "    if not d:\n",
    "        return \"intermediate\"\n",
    "    d = str(d).strip().lower()\n",
    "    if d.startswith(\"beg\"): return \"beginner\"\n",
    "    if d.startswith(\"inter\"): return \"intermediate\"\n",
    "    if d.startswith(\"adv\"): return \"advanced\"\n",
    "    if d.startswith(\"mast\"): return \"master\"\n",
    "    return d if d in {\"beginner\",\"intermediate\",\"advanced\",\"master\"} else \"intermediate\"\n",
    "\n",
    "DIFF_LEVELS = {\"beginner\": 0, \"intermediate\": 1, \"advanced\": 2, \"master\": 3}\n",
    "def _diff_level(d: Optional[str]) -> int:\n",
    "    return DIFF_LEVELS.get(_norm_diff(d), 1)\n",
    "\n",
    "def _diff_centered(level: int) -> float:\n",
    "    # beginner:-1, intermediate:-0.333..., advanced:+0.333..., master:+1\n",
    "    return (max(0, min(3, level)) - 1.5) / 1.5\n",
    "\n",
    "def _impact_with_difficulty(base_impact: float, correct: bool, level: int) -> float:\n",
    "    c = _diff_centered(level)  # [-1..+1]\n",
    "    k = 0.20\n",
    "    scale = (1.0 + k * c) if correct else (1.0 - k * c)\n",
    "    return max(0.5, min(5.0, base_impact * scale))\n",
    "\n",
    "def _mistakes_from_entry(entry: dict) -> int:\n",
    "    for key in (\"mistakes\",\"mistake_count\",\"num_mistakes\",\"attempts_before_correct\",\"attempts\"):\n",
    "        if key in entry and entry[key] is not None:\n",
    "            try:\n",
    "                return min(3, max(0, int(entry[key])))  # cap at 3\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be68d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BKTParams:\n",
    "    p_L0: float = 0.20\n",
    "    p_T: float = 0.10         # learning after observation\n",
    "    p_T_wrong: float = 0.02   # small learning from mistakes\n",
    "    p_S: float = 0.10         # slip\n",
    "    p_G: float = 0.20         # guess\n",
    "    decay_wrong: float = 0.90 # lighter forgetting baseline\n",
    "    min_floor: float = 0.001\n",
    "    max_ceiling: float = 0.999\n",
    "\n",
    "def _observe_params_with_difficulty(base: BKTParams, level: int):\n",
    "    # Small, bounded adjustments by difficulty + tighter bands\n",
    "    c = _diff_centered(level)           # [-1..+1]\n",
    "    s_k, g_k, d_k = 0.04, 0.04, 0.07\n",
    "    p_S_eff = max(0.06, min(0.14, base.p_S + s_k*c))\n",
    "    p_G_eff = max(0.12, min(0.28, base.p_G - g_k*c))\n",
    "    # Move decay toward 0.98 on hard, 0.80 on easy\n",
    "    target = 0.98 if c > 0 else 0.80\n",
    "    decay_eff = base.decay_wrong + d_k*(target - base.decay_wrong) + 0.05*c\n",
    "    decay_eff = max(0.80, min(0.98, decay_eff))\n",
    "    return p_S_eff, p_G_eff, decay_eff\n",
    "\n",
    "def bkt_update_once(p_know: float, correct: bool, p: BKTParams) -> float:\n",
    "    if correct:\n",
    "        num = p_know * (1.0 - p.p_S)\n",
    "        den = num + (1.0 - p_know) * p.p_G\n",
    "    else:\n",
    "        num = p_know * p.p_S\n",
    "        den = num + (1.0 - p_know) * (1.0 - p.p_G)\n",
    "    post = 0.0 if den == 0 else num / den\n",
    "    pT_use = p.p_T if correct else p.p_T_wrong\n",
    "    p_next = post + (1.0 - post) * pT_use\n",
    "    if not correct:\n",
    "        p_next *= p.decay_wrong\n",
    "    return max(p.min_floor, min(p.max_ceiling, p_next))\n",
    "\n",
    "def bkt_update_fractional(p_know: float, correct: bool, p: BKTParams, impact: float) -> float:\n",
    "    rounds = int(max(0, math.floor(impact)))\n",
    "    for _ in range(rounds):\n",
    "        p_know = bkt_update_once(p_know, correct, p)\n",
    "    frac = max(0.0, impact - rounds)\n",
    "    if frac > 1e-6:\n",
    "        p_soft = BKTParams(\n",
    "            p_L0=p.p_L0,\n",
    "            p_T=max(1e-6, min(0.95, p.p_T * frac)),\n",
    "            p_T_wrong=p.p_T_wrong,\n",
    "            p_S=p.p_S,\n",
    "            p_G=p.p_G,\n",
    "            decay_wrong=1.0 - (1.0 - p.decay_wrong) * frac,\n",
    "            min_floor=p.min_floor,\n",
    "            max_ceiling=p.max_ceiling,\n",
    "        )\n",
    "        p_know = bkt_update_once(p_know, correct, p_soft)\n",
    "    return p_know\n",
    "\n",
    "def _lr_mult_from_practice(wins: float, fails: float) -> float:\n",
    "    n = max(1.0, wins + fails)\n",
    "    perf = (wins - fails) / n  # [-1..+1]\n",
    "    m = 1.0 + 0.5 * perf       # [0.5..1.5]\n",
    "    return max(0.5, min(1.5, m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d725cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_p_correct(p_know: float, p_S: float, p_G: float) -> float:\n",
    "    return float(p_know * (1.0 - p_S) + (1.0 - p_know) * p_G)\n",
    "\n",
    "def evaluate_events(events: Iterable[dict], *, base_prior: float = 0.20) -> dict:\n",
    "    base = BKTParams(p_L0=base_prior)\n",
    "    user_state: Dict[int, Dict[int, float]] = {}     # user_id -> {subtopic_id: p_know}\n",
    "    extra_counters: Dict[Tuple[int,int], Tuple[float,float]] = {}  # (user, subtopic) -> (wins,fails)\n",
    "\n",
    "    rows: List[dict] = []\n",
    "    for e in list(events):\n",
    "        user_id = int(e.get(\"user_id\", 0) or 0)\n",
    "        subtopic_ids = e.get(\"subtopic_ids\") or []\n",
    "        if not user_id or not subtopic_ids:\n",
    "            continue\n",
    "\n",
    "        is_correct = bool(e.get(\"is_correct\", False))\n",
    "        difficulty = _norm_diff(e.get(\"estimated_difficulty\"))\n",
    "        level = _diff_level(difficulty)\n",
    "\n",
    "        p_S_eff, p_G_eff, decay_eff = _observe_params_with_difficulty(base, level)\n",
    "        mistakes = _mistakes_from_entry(e)\n",
    "\n",
    "        base_weight = float(_game_weight(e))\n",
    "        time_mult = _time_multiplier(e, is_correct)\n",
    "        impact_raw = base_weight * time_mult\n",
    "        impact = _impact_with_difficulty(impact_raw, is_correct, level)\n",
    "\n",
    "        k = max(1, len(subtopic_ids))\n",
    "        impact_each = impact / k\n",
    "\n",
    "        for s_id in subtopic_ids:\n",
    "            sub_map = user_state.setdefault(user_id, {})\n",
    "            p_know = sub_map.get(s_id, base_prior)\n",
    "\n",
    "            # Predict before update\n",
    "            p_pred = _predict_p_correct(p_know, p_S_eff, p_G_eff)\n",
    "            rows.append({\n",
    "                \"user_id\": user_id,\n",
    "                \"subtopic_id\": s_id,\n",
    "                \"is_correct\": int(is_correct),\n",
    "                \"p_correct\": float(np.clip(p_pred, 1e-9, 1-1e-9)),\n",
    "                \"game_type\": (e.get(\"game_type\") or \"\").strip().lower(),\n",
    "                \"estimated_difficulty\": difficulty,\n",
    "                \"minigame_type\": (e.get(\"minigame_type\") or \"\").strip().lower(),\n",
    "            })\n",
    "\n",
    "            # Lightweight practice counters for lr scaling\n",
    "            key = (user_id, s_id)\n",
    "            w, f = extra_counters.get(key, (0.0, 0.0))\n",
    "            if is_correct:\n",
    "                w += impact_each\n",
    "                f += impact_each * mistakes\n",
    "            else:\n",
    "                f += impact_each * (1 + mistakes)\n",
    "            extra_counters[key] = (w, f)\n",
    "            lr_mult = _lr_mult_from_practice(w, f)\n",
    "\n",
    "            # Update mastery\n",
    "            step = BKTParams(\n",
    "                p_L0=p_know,\n",
    "                p_T=max(1e-4, min(0.95, base.p_T * lr_mult)),\n",
    "                p_T_wrong=base.p_T_wrong,\n",
    "                p_S=p_S_eff,\n",
    "                p_G=p_G_eff,\n",
    "                decay_wrong=decay_eff,\n",
    "                min_floor=base.min_floor,\n",
    "                max_ceiling=base.max_ceiling,\n",
    "            )\n",
    "            new_p = bkt_update_fractional(p_know, is_correct, step, impact_each)\n",
    "            sub_map[s_id] = new_p\n",
    "\n",
    "    events_df = pd.DataFrame(rows)\n",
    "    return {\"events_df\": events_df, \"user_final_mastery\": user_state}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14748c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(y_true, y_pred) -> float:\n",
    "    eps = 1e-9\n",
    "    p = np.clip(np.asarray(y_pred, dtype=float), eps, 1 - eps)\n",
    "    y = np.asarray(y_true, dtype=float)\n",
    "    return float(np.mean(y * np.log(p) + (1 - y) * np.log(1 - p)))\n",
    "\n",
    "def _macro_user_auc(df: pd.DataFrame) -> Optional[float]:\n",
    "    aucs = []\n",
    "    for _, g in df.groupby(\"user_id\"):\n",
    "        y = g[\"is_correct\"].values\n",
    "        if len(np.unique(y)) < 2:\n",
    "            continue\n",
    "        aucs.append(roc_auc_score(y, g[\"p_correct\"].values))\n",
    "    return None if not aucs else float(np.mean(aucs))\n",
    "\n",
    "def metrics_overview(events_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    def _one(df: pd.DataFrame, name: str):\n",
    "        if len(df) == 0:\n",
    "            rows.append({\"group\": name, \"n\": 0, \"avg_log_likelihood\": np.nan, \"auc_roc\": np.nan, \"brier\": np.nan, \"macro_user_auc\": np.nan})\n",
    "            return\n",
    "        y, p = df[\"is_correct\"].values, df[\"p_correct\"].values\n",
    "        ll = log_likelihood(y, p)\n",
    "        auc = roc_auc_score(y, p) if len(np.unique(y)) == 2 else np.nan\n",
    "        brier = brier_score_loss(y, p)\n",
    "        mau = _macro_user_auc(df)\n",
    "        rows.append({\"group\": name, \"n\": int(len(df)), \"avg_log_likelihood\": ll, \"auc_roc\": auc, \"brier\": brier, \"macro_user_auc\": mau})\n",
    "\n",
    "    _one(events_df, \"OVERALL\")\n",
    "    for gt, g in events_df.groupby(\"game_type\"): _one(g, f\"game_type={gt}\")\n",
    "    for d, g in events_df.groupby(\"estimated_difficulty\"): _one(g, f\"difficulty={d}\")\n",
    "    return pd.DataFrame(rows).sort_values([\"group\"]).reset_index(drop=True)\n",
    "\n",
    "def breakdown_by(events_df: pd.DataFrame, group_col: str) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for name, g in events_df.groupby(group_col):\n",
    "        if len(g) == 0: continue\n",
    "        y, p = g[\"is_correct\"].values, g[\"p_correct\"].values\n",
    "        ll = log_likelihood(y, p)\n",
    "        auc = roc_auc_score(y, p) if len(np.unique(y)) == 2 else np.nan\n",
    "        brier = brier_score_loss(y, p)\n",
    "        out.append({group_col: name, \"n\": int(len(g)), \"log_likelihood\": ll, \"auc_roc\": auc, \"brier\": brier})\n",
    "    return pd.DataFrame(out).sort_values([group_col]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df662794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with real events from your DB/logs\n",
    "rng = np.random.default_rng(7)\n",
    "difficulties = [\"beginner\", \"intermediate\", \"advanced\", \"master\"]\n",
    "minigames = [\"crossword\", \"wordsearch\", \"debugging\", \"hangman\"]\n",
    "\n",
    "events = []\n",
    "for user_id in [1, 2, 3]:\n",
    "    for i in range(120):\n",
    "        mg = minigames[rng.integers(0, len(minigames))]\n",
    "        gt = \"coding\" if mg in {\"debugging\", \"hangman\"} else \"non_coding\"\n",
    "        events.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"question_id\": 1000 + i,\n",
    "            \"is_correct\": int(rng.random() < 0.7),\n",
    "            \"estimated_difficulty\": difficulties[rng.integers(0, len(difficulties))],\n",
    "            \"game_type\": gt,\n",
    "            \"minigame_type\": mg,\n",
    "            \"minigame_time_taken\": float(rng.uniform(50, 250)),\n",
    "            \"time_limit\": 300.0,\n",
    "            \"mistakes\": int(rng.integers(0, 3)),\n",
    "            \"subtopic_ids\": [int(rng.integers(1, 10))],\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d91371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subtopic_id</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>p_correct</th>\n",
       "      <th>game_type</th>\n",
       "      <th>estimated_difficulty</th>\n",
       "      <th>minigame_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>coding</td>\n",
       "      <td>advanced</td>\n",
       "      <td>hangman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>non_coding</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>crossword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177730</td>\n",
       "      <td>non_coding</td>\n",
       "      <td>master</td>\n",
       "      <td>crossword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>coding</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>debugging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>coding</td>\n",
       "      <td>master</td>\n",
       "      <td>debugging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  subtopic_id  is_correct  p_correct   game_type  \\\n",
       "0        1            3           0   0.326667      coding   \n",
       "1        1            8           0   0.353333  non_coding   \n",
       "2        1            3           1   0.177730  non_coding   \n",
       "3        1            5           1   0.353333      coding   \n",
       "4        1            9           0   0.300000      coding   \n",
       "\n",
       "  estimated_difficulty minigame_type  \n",
       "0             advanced       hangman  \n",
       "1         intermediate     crossword  \n",
       "2               master     crossword  \n",
       "3         intermediate     debugging  \n",
       "4               master     debugging  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evaluate_events(events)\n",
    "df = res[\"events_df\"]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b207539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>avg_log_likelihood</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>brier</th>\n",
       "      <th>macro_user_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVERALL</td>\n",
       "      <td>360</td>\n",
       "      <td>-0.828389</td>\n",
       "      <td>0.482565</td>\n",
       "      <td>0.289764</td>\n",
       "      <td>0.480666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>difficulty=advanced</td>\n",
       "      <td>85</td>\n",
       "      <td>-0.833101</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.291863</td>\n",
       "      <td>0.500817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>difficulty=beginner</td>\n",
       "      <td>89</td>\n",
       "      <td>-0.855633</td>\n",
       "      <td>0.426548</td>\n",
       "      <td>0.290165</td>\n",
       "      <td>0.400088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>difficulty=intermediate</td>\n",
       "      <td>88</td>\n",
       "      <td>-0.755457</td>\n",
       "      <td>0.566628</td>\n",
       "      <td>0.259539</td>\n",
       "      <td>0.579320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>difficulty=master</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.865051</td>\n",
       "      <td>0.445153</td>\n",
       "      <td>0.314719</td>\n",
       "      <td>0.427713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>game_type=coding</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.755356</td>\n",
       "      <td>0.561850</td>\n",
       "      <td>0.261752</td>\n",
       "      <td>0.559093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>game_type=non_coding</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.904742</td>\n",
       "      <td>0.396784</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.410105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     group    n  avg_log_likelihood   auc_roc     brier  \\\n",
       "0                  OVERALL  360           -0.828389  0.482565  0.289764   \n",
       "1      difficulty=advanced   85           -0.833101  0.459975  0.291863   \n",
       "2      difficulty=beginner   89           -0.855633  0.426548  0.290165   \n",
       "3  difficulty=intermediate   88           -0.755457  0.566628  0.259539   \n",
       "4        difficulty=master   98           -0.865051  0.445153  0.314719   \n",
       "5         game_type=coding  184           -0.755356  0.561850  0.261752   \n",
       "6     game_type=non_coding  176           -0.904742  0.396784  0.319048   \n",
       "\n",
       "   macro_user_auc  \n",
       "0        0.480666  \n",
       "1        0.500817  \n",
       "2        0.400088  \n",
       "3        0.579320  \n",
       "4        0.427713  \n",
       "5        0.559093  \n",
       "6        0.410105  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_overview(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d79926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_type</th>\n",
       "      <th>n</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coding</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.755356</td>\n",
       "      <td>0.561850</td>\n",
       "      <td>0.261752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_coding</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.904742</td>\n",
       "      <td>0.396784</td>\n",
       "      <td>0.319048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_type    n  log_likelihood   auc_roc     brier\n",
       "0      coding  184       -0.755356  0.561850  0.261752\n",
       "1  non_coding  176       -0.904742  0.396784  0.319048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown_by(df, \"game_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89f481f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated_difficulty</th>\n",
       "      <th>n</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advanced</td>\n",
       "      <td>85</td>\n",
       "      <td>-0.833101</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.291863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beginner</td>\n",
       "      <td>89</td>\n",
       "      <td>-0.855633</td>\n",
       "      <td>0.426548</td>\n",
       "      <td>0.290165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intermediate</td>\n",
       "      <td>88</td>\n",
       "      <td>-0.755457</td>\n",
       "      <td>0.566628</td>\n",
       "      <td>0.259539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>master</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.865051</td>\n",
       "      <td>0.445153</td>\n",
       "      <td>0.314719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimated_difficulty   n  log_likelihood   auc_roc     brier\n",
       "0             advanced  85       -0.833101  0.459975  0.291863\n",
       "1             beginner  89       -0.855633  0.426548  0.290165\n",
       "2         intermediate  88       -0.755457  0.566628  0.259539\n",
       "3               master  98       -0.865051  0.445153  0.314719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown_by(df, \"estimated_difficulty\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
